{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1.3.2 实现前馈神经网络语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from utils import BOS_TOKEN,EOS_TOKEN\n",
    "from utils import load_reuters,save_pretrained,get_loader,init_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建FNNLM的数据处理类\n",
    "# 该类将实现FNNLM的训练数据构建与存储功能\n",
    "class NGramDatasets(Dataset):\n",
    "    def __init__(self, corpus, vocab, context_size=2):\n",
    "        self.data = []\n",
    "        self.bos = vocab[BOS_TOKEN]\n",
    "        self.eos = vocab[EOS_TOKEN]\n",
    "        \n",
    "        for sentence in tqdm(corpus, desc=\"Dataset Construction\"):\n",
    "            # 插入句首和句尾符号\n",
    "            sentence = [self.bos] + sentence +[self.eos]\n",
    "            if len(sentence) < context_size:\n",
    "                continue\n",
    "            for i in range(context_size, len(sentence)):\n",
    "                #长度为context_size的上文\n",
    "                context = sentence[i-context_size:i]\n",
    "                target = sentence[i]\n",
    "                self.data.append((context,target))\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "    \n",
    "    def collate_fn(self, examples):\n",
    "        # 从独立样本集合中构建batch输入输出\n",
    "        inputs = torch.tensor([ex[0] for ex in examples], dtype=torch.long)\n",
    "        targets = torch.tensor([ex[1] for ex in examples], dtype=torch.long)\n",
    "        return (inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNNLM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size, hidden_dim):\n",
    "        super(FeedForwardNNLM, self).__init__()\n",
    "        # 词嵌入层\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # 词向量层到隐含层的线性变换\n",
    "        self.linear1 = nn.Linear(context_size*embedding_dim, hidden_dim)\n",
    "        # 隐含层到输出层的线性变换\n",
    "        self.linear2 = nn.Linear(hidden_dim, vocab_size)\n",
    "        # 词向量层到隐含层的激活函数\n",
    "        self.activate = F.relu\n",
    "        init_weights(self)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((inputs.shape[0],-1))\n",
    "        hidden = self.activate(self.linear1(embeds))\n",
    "        output = self.linear2(hidden)\n",
    "        \n",
    "        log_probs = F.log_softmax(output,dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "context_size = 2\n",
    "hidden_dim = 128\n",
    "batch_size = 1024\n",
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, vocab = load_reuters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a83394e4bb48b088bb7f954cf923f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dataset Construction:   0%|          | 0/54716 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 读取文本数据，构建FFNNLM训练数据集（n-grams）\n",
    "dataset = NGramDatasets(corpus,vocab,context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = get_loader(dataset,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 负对数似然损失函数\n",
    "nll_loss = nn.NLLLoss()\n",
    "# 构建FFNNLM并加载至device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = FeedForwardNNLM(len(vocab),embedding_dim,context_size,hidden_dim)\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "model.train()\n",
    "total_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ea5166a0354bcb876cc02e020a8ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 0:   0%|          | 0/1681 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9152.42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e44a1e23d654e9f9b32f2a1410a6caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1:   0%|          | 0/1681 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 7814.06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a5f497b1a643edbaf79dbd43c667d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2:   0%|          | 0/1681 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 7334.58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3b65c5529c40f9b64f5aefb9004697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3:   0%|          | 0/1681 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 7025.26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6d93d14fff4a54b6a6ffe915a402e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4:   0%|          | 0/1681 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6807.09\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9eb0c6c4d0431091d993a9202d559e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 5:   0%|          | 0/1681 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6647.92\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec84e09b9724dc4b2f55726682b7511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 6:   0%|          | 0/1681 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6529.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01dc4271ab45495a943f4fdcc1d1646d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 7:   0%|          | 0/1681 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6435.18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9218135a40c04de78cc5b322e27cc85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 8:   0%|          | 0/1681 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6357.48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15cc276453b240b1aeb829d172d1f985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 9:   0%|          | 0/1681 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6290.65\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(data_loader, desc = f\"Training Epoch {epoch}\"):\n",
    "        inputs, targets = [x.to(device) for x in batch]\n",
    "        optimizer.zero_grad()\n",
    "        log_probs = model(inputs)\n",
    "        loss = nll_loss(log_probs,targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Loss: {total_loss:.2f}\")\n",
    "    total_losses.append(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained embeddings saved to: ffnnlm.vec\n"
     ]
    }
   ],
   "source": [
    "# 词向量即model.embeddings，保存至ffnlm.vec文件\n",
    "save_pretrained(vocab, model.embeddings.weight.data, \"ffnnlm.vec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
