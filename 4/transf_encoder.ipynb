{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4.6 实现Transformer的EncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "encoder_layer=nn.TransformerEncoderLayer(d_model=4,nhead=2,dropout=0) #输入输出向量维度4，头数2，dropout=1时随机杀死神经元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8031, 0.1144, 0.5061, 0.1198],\n",
       "         [0.5887, 0.2661, 0.1660, 0.8181],\n",
       "         [0.0260, 0.1060, 0.4196, 0.9910]],\n",
       "\n",
       "        [[0.9976, 0.7593, 0.7309, 0.6850],\n",
       "         [0.4764, 0.3201, 0.2196, 0.6967],\n",
       "         [0.8215, 0.5914, 0.9969, 0.3840]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src=torch.rand(2,3,4) #序列长度2，批次3，输入向量维度4\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5792, -0.6922,  0.1194, -1.0064],\n",
       "         [ 0.8216, -1.2183, -0.7403,  1.1370],\n",
       "         [-0.5546, -1.2212,  0.3290,  1.4467]],\n",
       "\n",
       "        [[ 1.6074, -0.3891, -0.0980, -1.1203],\n",
       "         [ 0.7135, -1.3201, -0.5811,  1.1877],\n",
       "         [ 1.0008, -0.4621,  0.8795, -1.4182]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out=encoder_layer(src)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6992, -0.4190, -0.3976, -0.8826],\n",
       "         [ 1.7061, -0.7716, -0.6365, -0.2980],\n",
       "         [ 1.6443, -1.0186, -0.4904, -0.1352]],\n",
       "\n",
       "        [[ 1.6974, -0.4087, -0.3980, -0.8907],\n",
       "         [ 1.7068, -0.7867, -0.6098, -0.3103],\n",
       "         [ 1.6963, -0.3826, -0.4187, -0.8950]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_encoder=nn.TransformerEncoder(encoder_layer,num_layers=6) #六层encodeer层堆叠起来\n",
    "out=transformer_encoder(src)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6992, -0.4190, -0.3976, -0.8826],\n",
       "         [ 1.7061, -0.7716, -0.6365, -0.2980],\n",
       "         [ 1.6443, -1.0186, -0.4904, -0.1352]],\n",
       "\n",
       "        [[ 1.6974, -0.4087, -0.3980, -0.8907],\n",
       "         [ 1.7068, -0.7867, -0.6098, -0.3103],\n",
       "         [ 1.6963, -0.3826, -0.4187, -0.8950]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory=transformer_encoder(src) #即encoder的输出\n",
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_layer=nn.TransformerDecoderLayer(d_model=4,nhead=2)\n",
    "transformer_decoder=nn.TransformerDecoder(decoder_layer,num_layers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2131, 0.6187, 0.0100, 0.2392],\n",
       "         [0.6948, 0.4054, 0.8496, 0.3513],\n",
       "         [0.1382, 0.5718, 0.9628, 0.6984]],\n",
       "\n",
       "        [[0.6907, 0.5293, 0.3338, 0.7954],\n",
       "         [0.3124, 0.2722, 0.5124, 0.5377],\n",
       "         [0.5184, 0.9386, 0.3087, 0.4838]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_part=torch.rand(2,3,4)\n",
    "out_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3241,  1.4229, -0.4587, -1.2883],\n",
       "         [ 0.2707,  1.1623, -1.5966,  0.1637],\n",
       "         [ 0.7098,  1.2458, -1.1044, -0.8511]],\n",
       "\n",
       "        [[ 0.5318,  1.2586, -0.3803, -1.4101],\n",
       "         [ 0.3959,  1.4107, -1.2360, -0.5705],\n",
       "         [ 0.5871,  1.2994, -1.2493, -0.6373]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out=transformer_decoder(out_part,memory)\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
