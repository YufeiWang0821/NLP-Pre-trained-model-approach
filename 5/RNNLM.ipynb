{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1.3.3 实现循环神经网络语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm.auto import tqdm\n",
    "from utils import BOS_TOKEN,EOS_TOKEN,PAD_TOKEN\n",
    "from utils import load_reuters,save_pretrained,get_loader,init_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建RNNLM的数据处理类，实现训练数据的构建与存取\n",
    "# 使用序列预测的方式构建训练样本\n",
    "class RNNLMDataset(Dataset):\n",
    "    def __init__(self, corpus, vocab):\n",
    "        self.data = []\n",
    "        self.bos = vocab[BOS_TOKEN]\n",
    "        self.eos = vocab[EOS_TOKEN]\n",
    "        self.pad = vocab[PAD_TOKEN]\n",
    "        \n",
    "        for sentence in tqdm(corpus, desc=\"Dataset Construction\"):\n",
    "            # 输入序列，开头加上记号\n",
    "            input = [self.bos]+sentence\n",
    "            # 输出序列，结尾加上记号\n",
    "            target = sentence+[self.eos]\n",
    "            self.data.append((input,target))\n",
    "            \n",
    "    # Subclasses of Dataset must overwrite the 2 functions below\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "    \n",
    "    def collate_fn(self, examples):\n",
    "        # 从独立样本集合中构建batch输入输出\n",
    "        inputs = [torch.tensor(ex[0]) for ex in examples]\n",
    "        targets = [torch.tensor(ex[1]) for ex in examples]\n",
    "        \n",
    "        # 对batch内的样本进行padding使其具有相同长度\n",
    "        inputs = pad_sequence(inputs,batch_first=True,padding_value=self.pad)\n",
    "        targets = pad_sequence(targets,batch_first=True,padding_value=self.pad)\n",
    "        return (inputs,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLM(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_dim,hidden_dim):\n",
    "        super(RNNLM,self).__init__()\n",
    "        \n",
    "        # 词嵌入层\n",
    "        self.embeddings = nn.Embedding(vocab_size,embedding_dim)\n",
    "        # LSTM\n",
    "        self.rnn = nn.LSTM(embedding_dim,hidden_dim,batch_first=True)\n",
    "        # 输出层\n",
    "        self.output = nn.Linear(hidden_dim,vocab_size)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        embeds = self.embeddings(inputs)\n",
    "        hidden,_ = self.rnn(embeds)\n",
    "        output = self.output(hidden)\n",
    "        log_probs = F.log_softmax(output,dim=2)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "context_size = 2\n",
    "hidden_dim = 128\n",
    "batch_size = 1024\n",
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce161799943241009ad15d182b8ac90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dataset Construction:   0%|          | 0/54716 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 读取文本数据，构建FFNNLM训练数据集（n-grams）\n",
    "corpus, vocab = load_reuters()\n",
    "dataset = RNNLMDataset(corpus, vocab)\n",
    "data_loader = get_loader(dataset, batch_size)\n",
    "# 负对数似然损失函数，忽略pad_token处的损失\n",
    "nll_loss = nn.NLLLoss(ignore_index=dataset.pad)\n",
    "# 构建RNNLM，并加载至device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RNNLM(len(vocab), embedding_dim, hidden_dim)\n",
    "model.to(device)\n",
    "# 使用Adam优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(data_loader, desc=f\"Training Epoch {epoch}\"):\n",
    "        inputs, targets = [x.to(device) for x in batch]\n",
    "        optimizer.zero_grad()\n",
    "        log_probs = model(inputs)\n",
    "        loss = nll_loss(log_probs.view(-1, log_probs.shape[-1]), targets.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Loss: {total_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pretrained(vocab, model.embeddings.weight.data, \"rnnlm.vec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
