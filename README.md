# NLP-Pre-trained-model-approach
这里是我对《NLP Pre-trained model approach》这本书讲解内容的代码的复现。  
|章节笔记|标题|内容|
|---|---|---|
|[2](https://yufeiwang.notion.site/2-66a19364b6f74d77a0c4fe7fc6041941)|[自然语言处理基础](https://github.com/YufeiWang0821/NLP-Pre-trained-model-approach/tree/main/2)|文本表示、点互信息、奇异值分解、中文分词|
|[4](https://yufeiwang.notion.site/4-db21651b5dff4611abe55390b6f8a7e1)|[自然语言处理中的神经网络基础](https://github.com/YufeiWang0821/NLP-Pre-trained-model-approach/tree/main/4)|MLP、CNN、RNN、LSTM、Transformer以及它们在情感分类与词性标注问题中的应用|
|[5](https://yufeiwang.notion.site/5-1de0d7261f0c480296fa24935f50384c)|[静态词向量预训练模型](https://github.com/YufeiWang0821/NLP-Pre-trained-model-approach/tree/main/5)|NNLM、Word2Vec（CBOW和Skip-gram）、GloVe|
|[6](https://yufeiwang.notion.site/6-c5c28141de004610a0b81fcfb8287155)|[动态词向量预训练模型](https://github.com/YufeiWang0821/NLP-Pre-trained-model-approach/tree/main/6)|ELMo|
|[7](https://yufeiwang.notion.site/7-ca2b770e09f7442ca2b1eb4995b9694f)|[预训练语言模型](https://github.com/YufeiWang0821/NLP-Pre-trained-model-approach/tree/main/7)|BERT|
|[8](https://yufeiwang.notion.site/8-60cc38ea245c4006a3d9c0b24b231917)|[预训练语言模型进阶](https://github.com/YufeiWang0821/NLP-Pre-trained-model-approach/tree/main/8)|模型蒸馏与压缩|  

（未完结）
